{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# <center>Group Project 1: Supervised Learning</center>\n",
    "## <center>Josh Melton and Ivan Benitez</center>  \n",
    "\n",
    "### Part 2: Congressional Voting Data\n",
    "#### a) Data Preparation\n",
    "\n",
    "First, read the voting data csv into a pandas dataframe.  \n",
    "- The data contain yes/no voting records on various issues: 'y' is converted to 1 and 'n' to 0.\n",
    "- The class label column contains each congressperson's party affiliation. For simplicity, republican is converted to 1 and democrat to 0.\n",
    "- The data also contain missing values, encoded with a '?'. These values are converted to numpy NaN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "voting_data = pd.read_csv('voting_data.csv',\n",
    "                          header=0,\n",
    "                          index_col=False)\n",
    "\n",
    "voting_data.replace({'y': 1, 'n': 0, '?': np.NaN,\n",
    "                     'republican': 1, 'democrat': 0}, inplace=True)\n",
    "\n",
    "# voting_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three different methods for handling the missing data were used to create three versions of the dataset\n",
    "- Version 1: Remove rows with missing values\n",
    "- Version 2: Replace missing values with a third label (2)\n",
    "- Version 3: Replace missing values with the mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Version 1: Drop rows with NaN\n",
    "voting_data_v1 = voting_data.dropna(axis=0, how='any')\n",
    "labels_v1 = voting_data_v1['Class Name']\n",
    "features_v1 = voting_data_v1.drop('Class Name', axis=1)\n",
    "\n",
    "# Version 2: Replace NaN with third category (2)\n",
    "voting_data_v2 = voting_data.fillna(2)\n",
    "labels_v2 = voting_data_v2['Class Name']\n",
    "features_v2 = voting_data_v2.drop('Class Name', axis=1)\n",
    "\n",
    "# Version 3: Replace NaN with mode (most frequent)\n",
    "labels_v3 = voting_data['Class Name']\n",
    "features_v3 = voting_data.drop('Class Name', axis=1)\n",
    "\n",
    "imp = SimpleImputer(strategy='most_frequent')\n",
    "features_v3 = imp.fit_transform(features_v3)\n",
    "\n",
    "features = [features_v1, features_v2, features_v3]\n",
    "labels = [labels_v1, labels_v2, labels_v3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Functions to print formatted metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def print_metrics(labels, preds):\n",
    "    \"\"\"\n",
    "        Prints confusion matrix and metrics scores for a binary classification\n",
    "    \"\"\"\n",
    "    scores = metrics.precision_recall_fscore_support(labels, preds)\n",
    "    conf = metrics.confusion_matrix(labels, preds)\n",
    "    print(' ' * 4 + 'Confusion Matrix')\n",
    "    print(' ' * 17 + 'Predict Positive    Predict Negative')\n",
    "    print('Actual Positive         {}                 {}'.format(conf[1, 1], conf[1, 0]))\n",
    "    print('Actual Negative         {}                 {}'.format(conf[0, 1], conf[0, 0]))\n",
    "    print()\n",
    "    print('Accuracy: {:.3f}'.format(metrics.accuracy_score(labels, preds)))\n",
    "    print()\n",
    "    print(' ' * 4 + 'Classification Report')\n",
    "    print(' ' * 11 + 'Positive    Negative')\n",
    "    print('Num cases    {}           {}'.format(scores[3][1], scores[3][0]))\n",
    "    print('Precision    {:.2f}       {:.2f}'.format(scores[0][1], scores[0][0]))\n",
    "    print('Recall       {:.2f}       {:.2f}'.format(scores[1][1], scores[1][0]))\n",
    "    print('F1 Score     {:.2f}       {:.2f}'.format(scores[2][1], scores[2][0]))\n",
    "\n",
    "def print_cv_scores(results):\n",
    "    \"\"\"\n",
    "        Prints scoring metrics from cross-validation \n",
    "    \"\"\"\n",
    "    f1 = results['test_f1']\n",
    "    precision = results['test_precision']\n",
    "    recall = results['test_recall']\n",
    "    accuracy = results['test_accuracy']\n",
    "\n",
    "    print(' ' * 4 + 'Cross Validation Scores')\n",
    "    print(' ' * 9 + 'F1     Precision    Recall    Accuracy')\n",
    "    for i, (f, p, r, a) in enumerate(zip(f1, precision, recall, accuracy)):\n",
    "        print('Fold {}   {:.3f}    {:.3f}      {:.3f}     {:.3f}'.format(i+1, f, p, r, a))\n",
    "    print()\n",
    "    print('Mean F1: {:.3f}'.format(f1.mean()))\n",
    "    print('Mean Precision: {:.3f}'.format(precision.mean()))\n",
    "    print('Mean Recall: {:.3f}'.format(recall.mean()))\n",
    "    print('Mean Accuracy: {:.3f}'.format(accuracy.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Decision Tree and Naive Bayes Models\n",
    "\n",
    "For each version of the data, initialize and fit a Decision Tree classifier and a Naive Bayes model.  \n",
    "Evaluate the models on the test data and then run 5-fold cross validation on the whole data set.  \n",
    "F1, precision, recall, and accuracy scores are reported for each fold as well as the mean score across all folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Version 1: Decision Tree\n    Confusion Matrix\n                 Predict Positive    Predict Negative\nActual Positive         16                 0\nActual Negative         1                 30\n\nAccuracy: 0.979\n\n    Classification Report\n           Positive    Negative\nNum cases    16           31\nPrecision    0.94       1.00\nRecall       1.00       0.97\nF1 Score     0.97       0.98\n\n    Cross Validation Scores\n         F1     Precision    Recall    Accuracy\nFold 1   0.933    0.913      0.955     0.936\nFold 2   1.000    1.000      1.000     1.000\nFold 3   0.977    1.000      0.955     0.979\nFold 4   0.950    1.000      0.905     0.957\nFold 5   0.884    0.864      0.905     0.889\n\nMean F1: 0.949\nMean Precision: 0.955\nMean Recall: 0.944\nMean Accuracy: 0.952\n-------------------------\nVersion 1: Naive Bayes\n    Confusion Matrix\n                 Predict Positive    Predict Negative\nActual Positive         14                 2\nActual Negative         4                 27\n\nAccuracy: 0.872\n\n    Classification Report\n           Positive    Negative\nNum cases    16           31\nPrecision    0.78       0.93\nRecall       0.88       0.87\nF1 Score     0.82       0.90\n\n    Cross Validation Scores\n         F1     Precision    Recall    Accuracy\nFold 1   0.894    0.840      0.955     0.894\nFold 2   0.826    0.792      0.864     0.830\nFold 3   0.977    1.000      0.955     0.979\nFold 4   1.000    1.000      1.000     1.000\nFold 5   0.870    0.800      0.952     0.867\n\nMean F1: 0.913\nMean Precision: 0.886\nMean Recall: 0.945\nMean Accuracy: 0.914\n##################################################\nVersion 2: Decision Tree\n    Confusion Matrix\n                 Predict Positive    Predict Negative\nActual Positive         27                 1\nActual Negative         0                 59\n\nAccuracy: 0.989\n\n    Classification Report\n           Positive    Negative\nNum cases    28           59\nPrecision    1.00       0.98\nRecall       0.96       1.00\nF1 Score     0.98       0.99\n\n    Cross Validation Scores",
      "\n         F1     Precision    Recall    Accuracy\nFold 1   0.971    0.971      0.971     0.977\nFold 2   0.971    0.971      0.971     0.977\nFold 3   0.955    0.970      0.941     0.966\nFold 4   0.889    0.933      0.848     0.919\nFold 5   0.923    0.938      0.909     0.942\n\nMean F1: 0.942\nMean Precision: 0.956\nMean Recall: 0.928\nMean Accuracy: 0.956\n-------------------------\nVersion 2: Naive Bayes\n    Confusion Matrix\n                 Predict Positive    Predict Negative\nActual Positive         27                 1\nActual Negative         5                 54\n\nAccuracy: 0.931\n\n    Classification Report\n           Positive    Negative\nNum cases    28           59\nPrecision    0.84       0.98\nRecall       0.96       0.92\nF1 Score     0.90       0.95\n\n    Cross Validation Scores\n         F1     Precision    Recall    Accuracy\nFold 1   0.889    0.842      0.941     0.909\nFold 2   0.822    0.769      0.882     0.852\nFold 3   0.923    0.968      0.882     0.943\nFold 4   0.955    0.941      0.970     0.965\nFold 5   0.800    0.714      0.909     0.826\n\nMean F1: 0.878\nMean Precision: 0.847\nMean Recall: 0.917\nMean Accuracy: 0.899\n##################################################\nVersion 3: Decision Tree\n    Confusion Matrix\n                 Predict Positive    Predict Negative\nActual Positive         26                 2\nActual Negative         2                 57\n\nAccuracy: 0.954\n\n    Classification Report\n           Positive    Negative\nNum cases    28           59\nPrecision    0.93       0.97\nRecall       0.93       0.97\nF1 Score     0.93       0.97\n\n    Cross Validation Scores\n         F1     Precision    Recall    Accuracy\nFold 1   0.971    0.971      0.971     0.977\nFold 2   0.958    0.919      1.000     0.966\nFold 3   0.955    0.970      0.941     0.966\nFold 4   0.906    0.935      0.879     0.930\nFold 5   0.928    0.889      0.970     0.942\n\nMean F1: 0.943\nMean Precision: 0.937\nMean Recall: 0.952\nMean Accuracy: 0.956\n-------------------------\nVersion 3: Naive Bayes\n    Confusion Matrix\n                 Predict Positive    Predict Negative\nActual Positive         27                 1\nActual Negative         4                 55\n\nAccuracy: 0.943\n\n    Classification Report\n           Positive    Negative\nNum cases    28           59\nPrecision    0.87       0.98\nRecall       0.96       0.93\nF1 Score     0.92       0.96\n\n    Cross Validation Scores\n         F1     Precision    Recall    Accuracy\nFold 1   0.889    0.842      0.941     0.909\nFold 2   0.838    0.775      0.912     0.864\nFold 3   0.923    0.968      0.882     0.943\nFold 4   0.955    0.941      0.970     0.965\nFold 5   0.811    0.732      0.909     0.837\n\nMean F1: 0.883\nMean Precision: 0.852\nMean Recall: 0.923\nMean Accuracy: 0.904\n##################################################\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import sklearn.model_selection as ms\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "scoring = ['f1', 'precision', 'recall', 'accuracy']\n",
    "for i, (feat, lab) in enumerate(zip(features, labels)):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = ms.train_test_split(feat, lab,\n",
    "                                                           test_size=0.2,\n",
    "                                                           random_state=1776)\n",
    "\n",
    "    # Decision Tree model\n",
    "    print('Version {}: Decision Tree'.format(i+1))\n",
    "    tree = DecisionTreeClassifier(criterion='gini',\n",
    "                                  class_weight='balanced',\n",
    "                                  random_state=1916)\n",
    "    tree.fit(X_train, y_train)   \n",
    "\n",
    "    y_pred_tree = tree.predict(X_test)\n",
    "    print_metrics(y_test, y_pred_tree)\n",
    "    print()\n",
    "\n",
    "    tree_cv_scores = ms.cross_validate(tree, feat, lab,\n",
    "                                       cv=5, scoring=scoring)\n",
    "    print_cv_scores(tree_cv_scores)\n",
    "    print('-' * 25)\n",
    "\n",
    "    # Naive Bayes model\n",
    "    print('Version {}: Naive Bayes'.format(i+1))\n",
    "    bnb = BernoulliNB()\n",
    "    bnb.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_nb = bnb.predict(X_test)\n",
    "    print_metrics(y_test, y_pred_nb)\n",
    "    print()\n",
    "\n",
    "    bnb_cv_scores = ms.cross_validate(bnb, feat, lab,\n",
    "                                      cv=5, scoring=scoring)\n",
    "    print_cv_scores(bnb_cv_scores)\n",
    "    print('#' * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}