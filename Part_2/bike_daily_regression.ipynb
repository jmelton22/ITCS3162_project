{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# <center>Group Project 2: Regression and Page Rank</center>\n",
    "## <center>Josh Melton and Ivan Benitez</center>  \n",
    "\n",
    "### Part 1: Linear Regression and KNN implementation\n",
    "#### 1.2) Daily Data\n",
    "Utilize the same procedure but now with the daily data set.\n",
    "##### a) Data preparation\n",
    "First, read the daily bike data csv into a pandas dataframe:\n",
    "- Set the column names\n",
    "- Index using the 'instant' column\n",
    "- Parse the date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "daily_data = pd.read_csv('Bike-Sharing-Dataset/day.csv',\n",
    "                          header=0, index_col=0,\n",
    "                          parse_dates=[1])\n",
    "# daily_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract feature set by removing the date column and the label columns.  \n",
    "Store the column name for each label vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "features = daily_data.drop(['dteday', 'casual', 'registered', 'cnt'], axis=1)\n",
    "label_cols = ['casual', 'registered', 'cnt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b) Feature correlation with labels\n",
    "\n",
    "Calculate the correlation of each feature with the label vectors.  \n",
    "Plot the four features with the highest correlation with each label vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% %matplotlib inline\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1600x800 with 4 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1600x800 with 4 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1600x800 with 4 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "features_subset_cols = []\n",
    "for lab in label_cols:\n",
    "    labels = daily_data[lab]\n",
    "\n",
    "    # Calculate how correlated each feature is with the labels\n",
    "    corrs = features.corrwith(labels, axis=0,\n",
    "                              method='pearson')\n",
    "    # Sort by absolute value of correlation\n",
    "    order = corrs.abs().sort_values(ascending=False)\n",
    "    corrs = corrs[order.index]\n",
    "    # print(corrs)\n",
    "\n",
    "    # Extract the 5 feature names with highest correlation for each label\n",
    "    features_subset_cols.append(corrs.index[:5].tolist())\n",
    "    \n",
    "    # Plot scatter plot of 4 features with highest correlations\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(16, 8))\n",
    "    ind = 0\n",
    "    for row in [0, 1]:\n",
    "        for col in [0, 1]:\n",
    "            df_col = corrs.index[ind]\n",
    "            ax[row, col].scatter(features[df_col], labels, s=3)\n",
    "\n",
    "            ax[row, col].set_xlabel(df_col, fontweight='bold')\n",
    "            ax[row, col].set_ylabel(lab)\n",
    "\n",
    "            ax[row, col].text(0.05, 0.95, 'R = {:.4f}'.format(corrs[ind]),\n",
    "                              transform=ax[row, col].transAxes)\n",
    "            ind += 1\n",
    "    fig.suptitle(lab, fontweight='bold')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c) Linear Regression Models\n",
    "Fit linear regression models using:\n",
    "1. The single most correlated feature with the labels\n",
    "2. The five features most highly correlated with the labels\n",
    "3. The entire feature set (11 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Linear Regression models:\n\nLabel column: casual\n\nSingle most correlated feature: atemp\n\tMean Square Error      = 296287.763\n\tRoot Mean Square Error = 544.323\n\tMean Absolute Error    = 405.735\n\tMedian Absolute Error  = 308.336\n\tR^2                    = 0.201\n\nFive column subset:\n\tMean Square Error      = 141343.427\n\tRoot Mean Square Error = 375.957\n\tMean Absolute Error    = 285.774\n\tMedian Absolute Error  = 231.649\n\tR^2                    = 0.619\n\nFull feature set:\n\tMean Square Error      = 138692.506\n\tRoot Mean Square Error = 372.414\n\tMean Absolute Error    = 279.025\n\tMedian Absolute Error  = 210.118\n\tR^2                    = 0.626\n\n--------------------------------------------------\nLabel column: registered\n\nSingle most correlated feature: yr\n\tMean Square Error      = 1393949.052\n\tRoot Mean Square Error = 1180.656\n\tMean Absolute Error    = 987.080\n\tMedian Absolute Error  = 890.540\n\tR^2                    = 0.413\n\nFive column subset:\n\tMean Square Error      = 565692.750\n\tRoot Mean Square Error = 752.125\n\tMean Absolute Error    = 600.427\n\tMedian Absolute Error  = 500.204\n\tR^2                    = 0.762\n\nFull feature set:\n\tMean Square Error      = 504563.012\n\tRoot Mean Square Error = 710.326\n\tMean Absolute Error    = 552.188\n\tMedian Absolute Error  = 440.290\n\tR^2                    = 0.787\n\n--------------------------------------------------\nLabel column: cnt\n\nSingle most correlated feature: atemp\n\tMean Square Error      = 2612610.674\n\tRoot Mean Square Error = 1616.357\n\tMean Absolute Error    = 1329.019\n\tMedian Absolute Error  = 1178.108\n\tR^2                    = 0.234\n\nFive column subset:\n\tMean Square Error      = 854303.945\n\tRoot Mean Square Error = 924.286\n\tMean Absolute Error    = 716.537\n\tMedian Absolute Error  = 581.630\n\tR^2                    = 0.750\n\nFull feature set:\n\tMean Square Error      = 851613.152\n\tRoot Mean Square Error = 922.829\n\tMean Absolute Error    = 700.073\n\tMedian Absolute Error  = 534.018\n\tR^2                    = 0.750\n\n--------------------------------------------------\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import math\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "def print_metrics(y_true, y_preds):\n",
    "    mse = metrics.mean_squared_error(y_true, y_preds)\n",
    "    print('\\tMean Square Error      = {:.3f}'.format(mse))\n",
    "    print('\\tRoot Mean Square Error = {:.3f}'.format(math.sqrt(mse)))\n",
    "    print('\\tMean Absolute Error    = {:.3f}'.format(metrics.mean_absolute_error(y_true, y_preds)))\n",
    "    print('\\tMedian Absolute Error  = {:.3f}'.format(metrics.median_absolute_error(y_true, y_preds)))\n",
    "    print('\\tR^2                    = {:.3f}'.format(metrics.r2_score(y_true, y_preds)))\n",
    "\n",
    "\n",
    "string_dict = {0: 'Single most correlated feature:',\n",
    "               1: 'Five column subset:',\n",
    "               2: 'Full feature set:'}\n",
    "\n",
    "print('Linear Regression models:\\n')\n",
    "for i, lab in enumerate(label_cols):\n",
    "    labels = daily_data[lab]\n",
    "\n",
    "    best_feature_name = features_subset_cols[i][0]\n",
    "    best_feature = daily_data[best_feature_name].values.reshape(-1, 1)\n",
    "    features_subset = daily_data[features_subset_cols[i]]\n",
    "\n",
    "    print('Label column: {}\\n'.format(lab))\n",
    "    for j, f in enumerate([best_feature, features_subset, features]):\n",
    "        X_train, X_test, y_train, y_test = ms.train_test_split(f, labels,\n",
    "                                                               test_size=0.2,\n",
    "                                                               random_state=123)\n",
    "        \n",
    "        print(string_dict[j], best_feature_name) if j == 0 else print(string_dict[j])\n",
    "        \n",
    "        lin_reg = LinearRegression()\n",
    "        lin_reg.fit(X_train, y_train)\n",
    "    \n",
    "        lin_preds = lin_reg.predict(X_test)\n",
    "        print_metrics(y_test, lin_preds)\n",
    "        print()\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c) KNN Regression Models\n",
    "Fit KNN regression models using:\n",
    "1. The single most correlated feature with the labels\n",
    "2. The five features most highly correlated with the labels\n",
    "3. The entire feature set (11 features)\n",
    "\n",
    "Use cross validation to determine the best k value for each model, refitting based on the Mean Squared Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "KNN Regression models:\n\nLabel column: casual\n\nSingle most correlated feature: atemp\n",
      "\tBest k: {'n_neighbors': 21}\n\tMean Square Error      = 291554.575\n\tRoot Mean Square Error = 539.958\n\tMean Absolute Error    = 396.013\n\tMedian Absolute Error  = 308.381\n\tR^2                    = 0.214\n\nFive column subset:\n",
      "\tBest k: {'n_neighbors': 9}\n\tMean Square Error      = 95458.359\n\tRoot Mean Square Error = 308.963\n\tMean Absolute Error    = 211.196\n\tMedian Absolute Error  = 149.222\n\tR^2                    = 0.743\n\nFull feature set:\n",
      "\tBest k: {'n_neighbors': 5}\n\tMean Square Error      = 91642.356\n\tRoot Mean Square Error = 302.725\n\tMean Absolute Error    = 210.550\n\tMedian Absolute Error  = 148.200\n\tR^2                    = 0.753\n\n--------------------------------------------------\nLabel column: registered\n\nSingle most correlated feature: yr\n",
      "\tBest k: {'n_neighbors': 29}\n\tMean Square Error      = 1409005.116\n\tRoot Mean Square Error = 1187.015\n\tMean Absolute Error    = 963.373\n\tMedian Absolute Error  = 836.000\n\tR^2                    = 0.406\n\nFive column subset:\n",
      "\tBest k: {'n_neighbors': 9}\n\tMean Square Error      = 561659.892\n\tRoot Mean Square Error = 749.440\n\tMean Absolute Error    = 567.280\n\tMedian Absolute Error  = 496.000\n\tR^2                    = 0.763\n\nFull feature set:\n",
      "\tBest k: {'n_neighbors': 3}\n\tMean Square Error      = 603830.596\n\tRoot Mean Square Error = 777.065\n\tMean Absolute Error    = 566.227\n\tMedian Absolute Error  = 378.667\n\tR^2                    = 0.746\n\n--------------------------------------------------\nLabel column: cnt\n\nSingle most correlated feature: atemp\n",
      "\tBest k: {'n_neighbors': 29}\n\tMean Square Error      = 2385951.189\n\tRoot Mean Square Error = 1544.652\n\tMean Absolute Error    = 1293.626\n\tMedian Absolute Error  = 1179.276\n\tR^2                    = 0.301\n\nFive column subset:\n",
      "\tBest k: {'n_neighbors': 7}\n\tMean Square Error      = 575116.894\n\tRoot Mean Square Error = 758.365\n\tMean Absolute Error    = 587.417\n\tMedian Absolute Error  = 496.429\n\tR^2                    = 0.831\n\nFull feature set:\n",
      "\tBest k: {'n_neighbors': 3}\n\tMean Square Error      = 900333.350\n\tRoot Mean Square Error = 948.859\n\tMean Absolute Error    = 700.422\n\tMedian Absolute Error  = 488.000\n\tR^2                    = 0.736\n\n--------------------------------------------------\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "print('KNN Regression models:\\n')\n",
    "for i, lab in enumerate(label_cols):\n",
    "    labels = daily_data[lab]\n",
    "    \n",
    "    best_feature_name = features_subset_cols[i][0]\n",
    "    best_feature = daily_data[best_feature_name].values.reshape(-1, 1)\n",
    "    features_subset = daily_data[features_subset_cols[i]]\n",
    "\n",
    "    print('Label column: {}\\n'.format(lab))\n",
    "    for j, f in enumerate([best_feature, features_subset, features]):\n",
    "        X_train, X_test, y_train, y_test = ms.train_test_split(f, labels,\n",
    "                                                               test_size=0.2,\n",
    "                                                               random_state=123)\n",
    "        \n",
    "        print(string_dict[j], best_feature_name) if j == 0 else print(string_dict[j])\n",
    "        \n",
    "        knn_reg = ms.GridSearchCV(KNeighborsRegressor(),\n",
    "                                  param_grid={'n_neighbors': range(1, 30, 2)},\n",
    "                                  cv=5, scoring='neg_mean_squared_error',\n",
    "                                  refit=True)\n",
    "        knn_reg.fit(X_train, y_train)\n",
    "        print('\\tBest k:', knn_reg.best_params_)\n",
    "    \n",
    "        knn_preds = knn_reg.predict(X_test)\n",
    "        print_metrics(y_test, knn_preds)\n",
    "        print()\n",
    "    print('-' * 50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}